{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzo per la Manutenzione Predittiva\n",
    "Una volta rilevate le anomalie, si puÃ²:\n",
    "\n",
    "Identificare le tendenze che precedono gli eventi anomali per fare previsioni future.\n",
    "Integrare il modello con sistemi di avviso per notificare gli operatori in caso di anomalie.\n",
    "Ottimizzare le procedure di manutenzione basandoti sulle previsioni delle anomalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Caricamento dei dati\n",
    "data = pd.read_csv('measure_24_before_high_events_for_model_Indiium.csv', sep=';')\n",
    "\n",
    "# Normalizzazione dei dati\n",
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "# Parametri GAN\n",
    "latent_dim = 100\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "\n",
    "# Creazione del generatore\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(data.shape[1], activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Creazione del discriminatore\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Costruzione del GAN\n",
    "discriminator = build_discriminator((data.shape[1],))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "generator = build_generator(latent_dim)\n",
    "z = tf.keras.Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(img)\n",
    "\n",
    "combined = tf.keras.Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Addestramento del GAN\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.randint(0, data.shape[0], batch_size)\n",
    "    real_data = data.iloc[idx].values\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_data = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_data, np.zeros((batch_size, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch} | D Loss: {d_loss[0]} | D Acc.: {100 * d_loss[1]} | G Loss: {g_loss}\")\n",
    "\n",
    "# Rilevamento delle anomalie\n",
    "def detect_anomalies(data, generator, threshold=0.1):\n",
    "    noise = np.random.normal(0, 1, (len(data), latent_dim))\n",
    "    gen_data = generator.predict(noise)\n",
    "    reconstruction_error = np.mean(np.abs(data.values - gen_data), axis=1)\n",
    "    anomalies = reconstruction_error > threshold\n",
    "    return anomalies\n",
    "\n",
    "anomalies = detect_anomalies(data, generator)\n",
    "\n",
    "# Visualizzazione delle anomalie\n",
    "data['anomaly'] = anomalies\n",
    "print(data[data['anomaly'] == True])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
